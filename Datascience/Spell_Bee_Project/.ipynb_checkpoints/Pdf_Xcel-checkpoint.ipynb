{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        gradual       bedlam     gargantuan     gimmick     monopolize  \\\n",
       " 0     ferocious    shortfall          salsa     flannel          water   \n",
       " 1    frequently      cowlick        chaotic    cucumber       marathon   \n",
       " 2    permission  opinionated         shrimp   McMansion       omission   \n",
       " 3         towel       slogan        mandate     janitor         newbie   \n",
       " 4        sundae   triumphant         turret     lionize    spreadsheet   \n",
       " 5      ornament  parenthetic         pigeon   headdress         badger   \n",
       " 6       rooster     listener      satellite   ludicrous  fortification   \n",
       " 7         scold     guardian       parasite        pear          hydra   \n",
       " 8       organza     dwindled       favorite      system         grouse   \n",
       " 9       fragile      fraught  OR *favourite    pedigree          manta   \n",
       " 10       galaxy       sturdy        cascade       empty       astonish   \n",
       " 11    complaint    treadmill      dandelion      amulet    fashionista   \n",
       " 12      curries    originate         famous       guess        stubble   \n",
       " 13       tennis      forfend       pristine    magician         genius   \n",
       " 14    grumbling  OR forefend         golden      carrot         nuance   \n",
       " 15       garlic    eavesdrop        modesty      meteor        stencil   \n",
       " 16         hula      January      amphibian  distraught        penguin   \n",
       " 17  reactionary      scruple       jealousy     freight        freckle   \n",
       " 18     muscular        moxie       remedial    honeybee        blooper   \n",
       " 19      drizzle       winnow          vouch     blemish  misconception   \n",
       " 20     accurate    incentive         trivia     crumpet        lambkin   \n",
       " 21       studio      admirer       shoulder    blizzard        chowder   \n",
       " 22  illusionist    emotional          zebra      squirm      sunflower   \n",
       " 23      genetic         chia   butterscotch  harmonious      lambasted   \n",
       " 24       levity    raspberry          apron      lawyer     volumetric   \n",
       " 25     moisture        bogus         beagle     valiant       flattery   \n",
       " 26    toughness       recoup         kidney       purse         simmer   \n",
       " 27    tasteless     bookworm        wistful      raisin          whisk   \n",
       " 28       astute      veteran          raven     trumpet        bathtub   \n",
       " 29       turtle        erase       fructose        bias  fantastically   \n",
       " 30    Pinkerton    handcuffs         Amazon     lettuce        failure   \n",
       " 31      fortune       spinal      companion    shamrock      tolerable   \n",
       " 32     sluggard   demolition       panorama   Americana       mosquito   \n",
       " \n",
       "          target  \n",
       " 0        angora  \n",
       " 1       snippet  \n",
       " 2       ascribe  \n",
       " 3    hodgepodge  \n",
       " 4      verbiage  \n",
       " 5        nephew  \n",
       " 6        imbibe  \n",
       " 7         savvy  \n",
       " 8        reckon  \n",
       " 9       boorish  \n",
       " 10       tarmac  \n",
       " 11    iteration  \n",
       " 12      nurture  \n",
       " 13      volcano  \n",
       " 14    forensics  \n",
       " 15   miraculous  \n",
       " 16       trendy  \n",
       " 17   permafrost  \n",
       " 18      iceberg  \n",
       " 19       cactus  \n",
       " 20  nationalism  \n",
       " 21       leeway  \n",
       " 22     pilferer  \n",
       " 23   rollicking  \n",
       " 24        quart  \n",
       " 25      lactose  \n",
       " 26  domineering  \n",
       " 27        onion  \n",
       " 28      abandon  \n",
       " 29        vault  \n",
       " 30       junior  \n",
       " 31       hamlet  \n",
       " 32     jubilant  ]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabula\n",
    "df = tabula.read_pdf('Words_Bee.pdf', pages = 5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_options() got an unexpected keyword argument 'multiple_tables'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-781d63b1c30d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtabula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Words_Bee.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Words_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"4-8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmultiple_tables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tabula\\io.py\u001b[0m in \u001b[0;36mconvert_into\u001b[1;34m(input_path, output_path, output_format, java_options, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtemporary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tabula\\io.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(java_options, options, path, encoding)\u001b[0m\n\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mbuilt_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"java\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mjava_options\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"-jar\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_jar_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbuilt_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: build_options() got an unexpected keyword argument 'multiple_tables'"
     ]
    }
   ],
   "source": [
    "\n",
    "tabula.convert_into(\"Words_Bee.pdf\", \"Words_test.csv\", pages=\"4-8\",output_format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(20,10,120,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          DIFFICULTY LEVEL: ONE B\n",
       " 0  School Spelling Bee Study List]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [DIFFICULTY LEVEL: ONE BEE]\n",
       " Index: []]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(20,10,70,420))\n",
    "df_hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIFFICULTY LEVEL: ONE BEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DIFFICULTY LEVEL: ONE BEE]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [: ONE BEE]\n",
       " Index: []]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(30,331,70,420))\n",
    "df_hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>: ONE BEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [: ONE BEE]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=str(df_hdr[0]) \n",
    "type(x)\n",
    "#y=x.split()\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Empty', 'DataFrame', 'Columns:', '[:', 'ONE', 'BEE]', 'Index:', '[]']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bee =x.split()\n",
    "Bee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THREE\n",
      "THREE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new=tabula.read_pdf(\"Words_Bee.pdf\", pages=27,area=(30,331,70,420))\n",
    "x=str(df_new[0])\n",
    "num_lst =['ONE','TWO', 'THREE']\n",
    "for i in num_lst:\n",
    "    if i in x:\n",
    "        print(i)\n",
    "        column_val = i\n",
    "        break\n",
    "print(column_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[]\n",
      "outside loop: ONE\n",
      "outside loop: TWO\n",
      "outside loop: THREE\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [: ONE BEE]\n",
      "Index: []]\n",
      "outside loop: ONE\n",
      "xval ONE\n",
      "Page read\n",
      "[       gel      day    scorch       hear      sizzle    jotted\n",
      "0    train    upset     motor     sprint   hatchling   swirled\n",
      "1    sport   father   talking        awe        razz    amount\n",
      "2     rich      jam     money       afar    followed    sighed\n",
      "3      eel     mugs     couch       bowl      purple     sheen\n",
      "4     fans     fair    nibble      sweat      entire     worse\n",
      "5     dome   dinner   strands       cost    December  sandwich\n",
      "6     tall     rats   chapter      sleek      sudden       duo\n",
      "7   better      fed     chess     bottle     slither  gleaming\n",
      "8      hit      sir     slimy      smart      combed   repress\n",
      "9   peanut     boom    squeak     stared      patrol   clothes\n",
      "10    cake     wave    friend    plopped        epic    either\n",
      "11    bite    trunk    laptop     darted       vital      rely\n",
      "12    noon   sleepy     movie      angry      window     chose\n",
      "13   gummy     full     known   sidekick      pocket     belle\n",
      "14   sting     huge    suffer      stuff     project      else\n",
      "15     ray     born    double      least       goofy   picture\n",
      "16    dusk  jumping     watch     little    remember   prepare\n",
      "17    mops     damp      ahoy       felt      travel   percent\n",
      "18  thanks     from     dream     summer      cranky    afraid\n",
      "19    dash    hunch     whine  carefully      career    rescue\n",
      "20    skin     each     beans      would     disease       NaN\n",
      "21    star    shade     child   shambles      trophy       NaN\n",
      "22   began     ribs     space  taillight     theater       NaN\n",
      "23    grew  forever  princess    quicken  OR theatre       NaN\n",
      "24    fine   freeze     piper   presence     athlete       NaN]\n"
     ]
    }
   ],
   "source": [
    "for pg in range(3,5):\n",
    "    print(pg)\n",
    "    df_new=tabula.read_pdf(\"Words_Bee.pdf\", pages=pg,area=(30,331,70,420))\n",
    "    x=str(df_new)\n",
    "    print(x)\n",
    "    def Lvl_chk(x):\n",
    "        num_lst =['ONE','TWO', 'THREE']\n",
    "        column_val=''\n",
    "    \n",
    "        for i in num_lst:\n",
    "            print('outside loop:',i)\n",
    "            if i in x:\n",
    "                print('xval',i)\n",
    "                column_val = i\n",
    "                return column_val\n",
    "        return None\n",
    "    \n",
    "    column_val =Lvl_chk(x)\n",
    "    if column_val:\n",
    "        print('Page read')\n",
    "        df_data=tabula.read_pdf(\"Words_Bee.pdf\",pages=pg)\n",
    "        print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Inp = {column_val : df_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'upset', 'motor', 'sprint', 'hatchling', 'swirled',\n",
       "       'sport', 'father', 'talking', 'awe', 'razz', 'amount', 'rich',\n",
       "       'jam', 'money', 'afar', 'followed', 'sighed', 'eel', 'mugs',\n",
       "       'couch', 'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble',\n",
       "       'sweat', 'entire', 'worse', 'dome', 'dinner', 'strands', 'cost',\n",
       "       'December', 'sandwich', 'tall', 'rats', 'chapter', 'sleek',\n",
       "       'sudden', 'duo', 'better', 'fed', 'chess', 'bottle', 'slither',\n",
       "       'gleaming', 'hit', 'sir', 'slimy', 'smart', 'combed', 'repress',\n",
       "       'peanut', 'boom', 'squeak', 'stared', 'patrol', 'clothes', 'cake',\n",
       "       'wave', 'friend', 'plopped', 'epic', 'either', 'bite', 'trunk',\n",
       "       'laptop', 'darted', 'vital', 'rely', 'noon', 'sleepy', 'movie',\n",
       "       'angry', 'window', 'chose', 'gummy', 'full', 'known', 'sidekick',\n",
       "       'pocket', 'belle', 'sting', 'huge', 'suffer', 'stuff', 'project',\n",
       "       'else', 'ray', 'born', 'double', 'least', 'goofy', 'picture',\n",
       "       'dusk', 'jumping', 'watch', 'little', 'remember', 'prepare',\n",
       "       'mops', 'damp', 'ahoy', 'felt', 'travel', 'percent', 'thanks',\n",
       "       'from', 'dream', 'summer', 'cranky', 'afraid', 'dash', 'hunch',\n",
       "       'whine', 'carefully', 'career', 'rescue', 'skin', 'each', 'beans',\n",
       "       'would', 'disease', nan, 'star', 'shade', 'child', 'shambles',\n",
       "       'trophy', nan, 'began', 'ribs', 'space', 'taillight', 'theater',\n",
       "       nan, 'grew', 'forever', 'princess', 'quicken', 'OR theatre', nan,\n",
       "       'fine', 'freeze', 'piper', 'presence', 'athlete', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample =np.array(df_data[0])\n",
    "\n",
    "\n",
    "new_list= np.concatenate( sample, axis=0 )\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.DataFrame(new_list,columns=[column_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hatchling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>freeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ONE\n",
       "0        train\n",
       "1        upset\n",
       "2        motor\n",
       "3       sprint\n",
       "4    hatchling\n",
       "..         ...\n",
       "145     freeze\n",
       "146      piper\n",
       "147   presence\n",
       "148    athlete\n",
       "149        NaN\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-16889f67b5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtabula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Words_Bee.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "df_data=tabula.read_pdf(\"Words_Bee.pdf\",pages=4)\n",
    "df_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gel</th>\n",
       "      <th>day</th>\n",
       "      <th>scorch</th>\n",
       "      <th>hear</th>\n",
       "      <th>sizzle</th>\n",
       "      <th>jotted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>upset</td>\n",
       "      <td>motor</td>\n",
       "      <td>sprint</td>\n",
       "      <td>hatchling</td>\n",
       "      <td>swirled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>father</td>\n",
       "      <td>talking</td>\n",
       "      <td>awe</td>\n",
       "      <td>razz</td>\n",
       "      <td>amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rich</td>\n",
       "      <td>jam</td>\n",
       "      <td>money</td>\n",
       "      <td>afar</td>\n",
       "      <td>followed</td>\n",
       "      <td>sighed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eel</td>\n",
       "      <td>mugs</td>\n",
       "      <td>couch</td>\n",
       "      <td>bowl</td>\n",
       "      <td>purple</td>\n",
       "      <td>sheen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fans</td>\n",
       "      <td>fair</td>\n",
       "      <td>nibble</td>\n",
       "      <td>sweat</td>\n",
       "      <td>entire</td>\n",
       "      <td>worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dome</td>\n",
       "      <td>dinner</td>\n",
       "      <td>strands</td>\n",
       "      <td>cost</td>\n",
       "      <td>December</td>\n",
       "      <td>sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tall</td>\n",
       "      <td>rats</td>\n",
       "      <td>chapter</td>\n",
       "      <td>sleek</td>\n",
       "      <td>sudden</td>\n",
       "      <td>duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>better</td>\n",
       "      <td>fed</td>\n",
       "      <td>chess</td>\n",
       "      <td>bottle</td>\n",
       "      <td>slither</td>\n",
       "      <td>gleaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit</td>\n",
       "      <td>sir</td>\n",
       "      <td>slimy</td>\n",
       "      <td>smart</td>\n",
       "      <td>combed</td>\n",
       "      <td>repress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peanut</td>\n",
       "      <td>boom</td>\n",
       "      <td>squeak</td>\n",
       "      <td>stared</td>\n",
       "      <td>patrol</td>\n",
       "      <td>clothes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cake</td>\n",
       "      <td>wave</td>\n",
       "      <td>friend</td>\n",
       "      <td>plopped</td>\n",
       "      <td>epic</td>\n",
       "      <td>either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bite</td>\n",
       "      <td>trunk</td>\n",
       "      <td>laptop</td>\n",
       "      <td>darted</td>\n",
       "      <td>vital</td>\n",
       "      <td>rely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>noon</td>\n",
       "      <td>sleepy</td>\n",
       "      <td>movie</td>\n",
       "      <td>angry</td>\n",
       "      <td>window</td>\n",
       "      <td>chose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gummy</td>\n",
       "      <td>full</td>\n",
       "      <td>known</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>pocket</td>\n",
       "      <td>belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sting</td>\n",
       "      <td>huge</td>\n",
       "      <td>suffer</td>\n",
       "      <td>stuff</td>\n",
       "      <td>project</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ray</td>\n",
       "      <td>born</td>\n",
       "      <td>double</td>\n",
       "      <td>least</td>\n",
       "      <td>goofy</td>\n",
       "      <td>picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dusk</td>\n",
       "      <td>jumping</td>\n",
       "      <td>watch</td>\n",
       "      <td>little</td>\n",
       "      <td>remember</td>\n",
       "      <td>prepare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mops</td>\n",
       "      <td>damp</td>\n",
       "      <td>ahoy</td>\n",
       "      <td>felt</td>\n",
       "      <td>travel</td>\n",
       "      <td>percent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thanks</td>\n",
       "      <td>from</td>\n",
       "      <td>dream</td>\n",
       "      <td>summer</td>\n",
       "      <td>cranky</td>\n",
       "      <td>afraid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dash</td>\n",
       "      <td>hunch</td>\n",
       "      <td>whine</td>\n",
       "      <td>carefully</td>\n",
       "      <td>career</td>\n",
       "      <td>rescue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>skin</td>\n",
       "      <td>each</td>\n",
       "      <td>beans</td>\n",
       "      <td>would</td>\n",
       "      <td>disease</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>star</td>\n",
       "      <td>shade</td>\n",
       "      <td>child</td>\n",
       "      <td>shambles</td>\n",
       "      <td>trophy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>began</td>\n",
       "      <td>ribs</td>\n",
       "      <td>space</td>\n",
       "      <td>taillight</td>\n",
       "      <td>theater</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>grew</td>\n",
       "      <td>forever</td>\n",
       "      <td>princess</td>\n",
       "      <td>quicken</td>\n",
       "      <td>OR theatre</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fine</td>\n",
       "      <td>freeze</td>\n",
       "      <td>piper</td>\n",
       "      <td>presence</td>\n",
       "      <td>athlete</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gel      day    scorch       hear      sizzle    jotted\n",
       "0    train    upset     motor     sprint   hatchling   swirled\n",
       "1    sport   father   talking        awe        razz    amount\n",
       "2     rich      jam     money       afar    followed    sighed\n",
       "3      eel     mugs     couch       bowl      purple     sheen\n",
       "4     fans     fair    nibble      sweat      entire     worse\n",
       "5     dome   dinner   strands       cost    December  sandwich\n",
       "6     tall     rats   chapter      sleek      sudden       duo\n",
       "7   better      fed     chess     bottle     slither  gleaming\n",
       "8      hit      sir     slimy      smart      combed   repress\n",
       "9   peanut     boom    squeak     stared      patrol   clothes\n",
       "10    cake     wave    friend    plopped        epic    either\n",
       "11    bite    trunk    laptop     darted       vital      rely\n",
       "12    noon   sleepy     movie      angry      window     chose\n",
       "13   gummy     full     known   sidekick      pocket     belle\n",
       "14   sting     huge    suffer      stuff     project      else\n",
       "15     ray     born    double      least       goofy   picture\n",
       "16    dusk  jumping     watch     little    remember   prepare\n",
       "17    mops     damp      ahoy       felt      travel   percent\n",
       "18  thanks     from     dream     summer      cranky    afraid\n",
       "19    dash    hunch     whine  carefully      career    rescue\n",
       "20    skin     each     beans      would     disease       NaN\n",
       "21    star    shade     child   shambles      trophy       NaN\n",
       "22   began     ribs     space  taillight     theater       NaN\n",
       "23    grew  forever  princess    quicken  OR theatre       NaN\n",
       "24    fine   freeze     piper   presence     athlete       NaN"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       gel      day    scorch       hear      sizzle    jotted\n",
       " 0    train    upset     motor     sprint   hatchling   swirled\n",
       " 1    sport   father   talking        awe        razz    amount\n",
       " 2     rich      jam     money       afar    followed    sighed\n",
       " 3      eel     mugs     couch       bowl      purple     sheen\n",
       " 4     fans     fair    nibble      sweat      entire     worse\n",
       " 5     dome   dinner   strands       cost    December  sandwich\n",
       " 6     tall     rats   chapter      sleek      sudden       duo\n",
       " 7   better      fed     chess     bottle     slither  gleaming\n",
       " 8      hit      sir     slimy      smart      combed   repress\n",
       " 9   peanut     boom    squeak     stared      patrol   clothes\n",
       " 10    cake     wave    friend    plopped        epic    either\n",
       " 11    bite    trunk    laptop     darted       vital      rely\n",
       " 12    noon   sleepy     movie      angry      window     chose\n",
       " 13   gummy     full     known   sidekick      pocket     belle\n",
       " 14   sting     huge    suffer      stuff     project      else\n",
       " 15     ray     born    double      least       goofy   picture\n",
       " 16    dusk  jumping     watch     little    remember   prepare\n",
       " 17    mops     damp      ahoy       felt      travel   percent\n",
       " 18  thanks     from     dream     summer      cranky    afraid\n",
       " 19    dash    hunch     whine  carefully      career    rescue\n",
       " 20    skin     each     beans      would     disease       NaN\n",
       " 21    star    shade     child   shambles      trophy       NaN\n",
       " 22   began     ribs     space  taillight     theater       NaN\n",
       " 23    grew  forever  princess    quicken  OR theatre       NaN\n",
       " 24    fine   freeze     piper   presence     athlete       NaN]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*df_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list=[]\n",
    "for item in df_data:\n",
    "    sample_list= ','.join(item)\n",
    "   \n",
    "\n",
    "hdr_lst=sample_list.split(',')\n",
    "hdr_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted', 'train',\n",
       "       'upset', 'motor', 'sprint', 'hatchling', 'swirled', 'sport',\n",
       "       'father', 'talking', 'awe', 'razz', 'amount', 'rich', 'jam',\n",
       "       'money', 'afar', 'followed', 'sighed', 'eel', 'mugs', 'couch',\n",
       "       'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble', 'sweat',\n",
       "       'entire', 'worse', 'dome', 'dinner', 'strands', 'cost', 'December',\n",
       "       'sandwich', 'tall', 'rats', 'chapter', 'sleek', 'sudden', 'duo',\n",
       "       'better', 'fed', 'chess', 'bottle', 'slither', 'gleaming', 'hit',\n",
       "       'sir', 'slimy', 'smart', 'combed', 'repress', 'peanut', 'boom',\n",
       "       'squeak', 'stared', 'patrol', 'clothes', 'cake', 'wave', 'friend',\n",
       "       'plopped', 'epic', 'either', 'bite', 'trunk', 'laptop', 'darted',\n",
       "       'vital', 'rely', 'noon', 'sleepy', 'movie', 'angry', 'window',\n",
       "       'chose', 'gummy', 'full', 'known', 'sidekick', 'pocket', 'belle',\n",
       "       'sting', 'huge', 'suffer', 'stuff', 'project', 'else', 'ray',\n",
       "       'born', 'double', 'least', 'goofy', 'picture', 'dusk', 'jumping',\n",
       "       'watch', 'little', 'remember', 'prepare', 'mops', 'damp', 'ahoy',\n",
       "       'felt', 'travel', 'percent', 'thanks', 'from', 'dream', 'summer',\n",
       "       'cranky', 'afraid', 'dash', 'hunch', 'whine', 'carefully',\n",
       "       'career', 'rescue', 'skin', 'each', 'beans', 'would', 'disease',\n",
       "       nan, 'star', 'shade', 'child', 'shambles', 'trophy', nan, 'began',\n",
       "       'ribs', 'space', 'taillight', 'theater', nan, 'grew', 'forever',\n",
       "       'princess', 'quicken', 'OR theatre', nan, 'fine', 'freeze',\n",
       "       'piper', 'presence', 'athlete', nan], dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1=np.array(hdr_lst)\n",
    "sample =np.array(df_data[0])\n",
    "\n",
    "\n",
    "new_list= np.concatenate( sample, axis=0 )\n",
    "merged=np.append(arr1,sample)\n",
    "merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
