{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title case printing : Hi Mumtaz \n"
     ]
    }
   ],
   "source": [
    "class sample():\n",
    "    def __init__(self,x):\n",
    "        self.word =x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Title case printing : {self.word.title()} \"\n",
    "s1 = sample('hi mumtaz')\n",
    "\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defination of the said word:\n",
      "with rapid movements\n",
      "\n",
      "Examples of the word in use::\n",
      "['he works quickly']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet \n",
    "syns1 = wordnet.synsets(\"quickly\")\n",
    "print(\"Defination of the said word:\")\n",
    "print(syns1[0].definition())\n",
    "print(\"\\nExamples of the word in use::\")\n",
    "print(syns1[0].examples())\n",
    "syns2 = wordnet.synsets(\"wonderful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('quickly.r.01'), Synset('promptly.r.01'), Synset('cursorily.r.01')]\n",
      "[Synset('fantastic.s.02')]\n"
     ]
    }
   ],
   "source": [
    "print(syns1)\n",
    "print(syns2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazing : v\n",
      "interesting : v\n",
      "love : n\n",
      "great : n\n",
      "nice : n\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "words = ['amazing', 'interesting', 'love', 'great', 'nice']\n",
    "\n",
    "for w in words:\n",
    "    tmp = wn.synsets(w)[0].pos()\n",
    "    print(w, \":\", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "Bee_201920_df = pd.read_csv('Bee_Docs/Bee_Word_2019-20.csv',index_col='Index')\n",
    "from random import sample\n",
    "\n",
    "# given data frame df\n",
    "\n",
    "# create random index\n",
    "rindex =  np.array(sample(range(len(Bee_201920_df)), 10))\n",
    "\n",
    "# get 10 random rows from df\n",
    "dfr = Bee_201920_df.index[rindex]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index\n",
       "0           punting\n",
       "1             crowd\n",
       "2            secret\n",
       "3            fumble\n",
       "4              pond\n",
       "           ...     \n",
       "451        jodhpurs\n",
       "452     hydrargyrum\n",
       "453       carborane\n",
       "454    denouncement\n",
       "455        Columbia\n",
       "Name: Words, Length: 456, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list =Bee_201920_df['Words']\n",
    "words_list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-86af58dd41ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#print('list: ', words_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdict_set\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mBee_201920_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Words'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdict_set\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_set\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m  \u001b[1;33m]\u001b[0m\u001b[1;31m# dropping None or empty values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdict_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdict_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'v'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'verb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'adjective'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'noun'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'adverb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'noun'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1479\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "\n",
    "#words_list['Sample_Words'] =Bee_201920_df['Words']\n",
    "\n",
    "#print('list: ', words_list)\n",
    "dict_set  = Bee_201920_df['Words'].apply(lambda w : wn.synsets(w))\n",
    "dict_set.dropna(axis=0,inplace=True)\n",
    "\n",
    "def dict_convert(dict_set):\n",
    "    dict_type={'v': 'verb','a':'adjective', 'n':'noun','r':'adverb','s': 'noun'}\n",
    "    x=[]\n",
    "    for each in dict_set:\n",
    "        x.append(dict_type[each[0].pos()])\n",
    "    return np.array(x)\n",
    "words_list['Sample_Types'] = pd.Series({\"Dict_Type\": dict_convert(dict_set)})\n",
    "    #print(each[0].pos())\n",
    "#    print(type(each[0]))\n",
    "#    print('word:',w,' word type',dict_type[each[0].pos()])\n",
    "#print('original type',Bee_201920_df.iloc[dfr,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_set.dropna(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word profound  word type adjective\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word culminate  word type verb\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word remarkable  word type subject\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word grub  word type noun\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word arrange  word type verb\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word opportunity  word type noun\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word social  word type noun\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word haughty  word type subject\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n",
      "word teak  word type noun\n",
      "original type Index\n",
      "206    adjective\n",
      "383         verb\n",
      "301    adjective\n",
      "70          noun\n",
      "282         verb\n",
      "411         noun\n",
      "87     adjective\n",
      "409    adjective\n",
      "155         noun\n",
      "453         noun\n",
      "Name: Type, dtype: object\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-1734c9d58c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mBee_201920_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' word type'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "dict_type={'v': 'verb','a':'adjective', 'n':'noun','r':'adverb','s': 'subject'}\n",
    "\n",
    "for w in Bee_201920_df.iloc[dfr,0]:\n",
    "    tmp = wn.synsets(w)[0].pos()\n",
    "    \n",
    "    print('word',w,' word type',dict_type[tmp])\n",
    "    print('original type',Bee_201920_df.iloc[dfr,1])\n",
    "from nltk.corpus import wordnet as wn\n",
    "dict_type={'v': 'verb','a':'adjective', 'n':'noun','r':'adverb','s': 'noun'}\n",
    "#words_list =np.array(Bee_201920_df.iloc[dfr,0])\n",
    "words_list=['profound', 'culminate', 'remarkable', 'grub', 'arrange','opportunity', 'social', 'haughty', 'teak', 'carborane']\n",
    "def word_find(w):\n",
    "    return wn.synsets(w)\n",
    "\n",
    "dictset=[]    \n",
    "for w in words_list:\n",
    "    dictset.append(word_find(w))\n",
    "\n",
    "dictset =[x for x in dictset or '' or [] if x  ]# dropping None or empty values\n",
    "    \n",
    "    #print(each[0].pos())\n",
    "#    print(type(each[0]))\n",
    "    print('word:',w,' word type',dict_type[each[0].pos()])\n",
    "#print('original type',Bee_201920_df.iloc[dfr,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
