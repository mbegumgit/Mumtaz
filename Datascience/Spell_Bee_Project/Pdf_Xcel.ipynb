{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "#df = tabula.read_pdf('Words_Bee.pdf', pages = 5)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Bee_Docs/Bee_Word_2020_decrypt.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a745f2349bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtabula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bee_Docs/Bee_Word_2020_decrypt.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Bee_Docs/2020_Words of the Champions_Output.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"1-2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tabula\\io.py\u001b[0m in \u001b[0;36mconvert_into\u001b[1;34m(input_path, output_path, output_format, java_options, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Bee_Docs/Bee_Word_2020_decrypt.pdf'"
     ]
    }
   ],
   "source": [
    "\n",
    "tabula.convert_into(\"Bee_Docs/Bee_Word_2020_decrypt.pdf\", \"Bee_Docs/2020_Words of the Champions_Output.csv\", pages=\"1-2\",output_format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(20,10,120,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df_hdr\n",
    "df_hdr2=tabula.read_pdf(\"Words_Bee.pdf\", pages=22,area=(30,331,70,420))\n",
    "if 'THREE' in str(df_hdr2):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [DIFFICULTY LEVEL: ONE BEE]\n",
       " Index: []]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(20,10,70,420))\n",
    "df_hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIFFICULTY LEVEL: ONE BEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DIFFICULTY LEVEL: ONE BEE]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [: ONE BEE]\n",
       " Index: []]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr=tabula.read_pdf(\"Words_Bee.pdf\", pages=4,area=(30,331,70,420))\n",
    "df_hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>: ONE BEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [: ONE BEE]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hdr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=str(df_hdr[0]) \n",
    "type(x)\n",
    "#y=x.split()\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Empty', 'DataFrame', 'Columns:', '[:', 'ONE', 'BEE]', 'Index:', '[]']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bee =x.split()\n",
    "Bee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THREE\n",
      "THREE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new=tabula.read_pdf(\"Words_Bee.pdf\", pages=27,area=(30,331,70,420))\n",
    "x=str(df_new[0])\n",
    "num_lst =['ONE','TWO', 'THREE']\n",
    "for i in num_lst:\n",
    "    if i in x:\n",
    "        print(i)\n",
    "        column_val = i\n",
    "        break\n",
    "print(column_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[]\n",
      "outside loop: ONE\n",
      "outside loop: TWO\n",
      "outside loop: THREE\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [: ONE BEE]\n",
      "Index: []]\n",
      "outside loop: ONE\n",
      "xval ONE\n",
      "Page read\n",
      "[       gel      day    scorch       hear      sizzle    jotted\n",
      "0    train    upset     motor     sprint   hatchling   swirled\n",
      "1    sport   father   talking        awe        razz    amount\n",
      "2     rich      jam     money       afar    followed    sighed\n",
      "3      eel     mugs     couch       bowl      purple     sheen\n",
      "4     fans     fair    nibble      sweat      entire     worse\n",
      "5     dome   dinner   strands       cost    December  sandwich\n",
      "6     tall     rats   chapter      sleek      sudden       duo\n",
      "7   better      fed     chess     bottle     slither  gleaming\n",
      "8      hit      sir     slimy      smart      combed   repress\n",
      "9   peanut     boom    squeak     stared      patrol   clothes\n",
      "10    cake     wave    friend    plopped        epic    either\n",
      "11    bite    trunk    laptop     darted       vital      rely\n",
      "12    noon   sleepy     movie      angry      window     chose\n",
      "13   gummy     full     known   sidekick      pocket     belle\n",
      "14   sting     huge    suffer      stuff     project      else\n",
      "15     ray     born    double      least       goofy   picture\n",
      "16    dusk  jumping     watch     little    remember   prepare\n",
      "17    mops     damp      ahoy       felt      travel   percent\n",
      "18  thanks     from     dream     summer      cranky    afraid\n",
      "19    dash    hunch     whine  carefully      career    rescue\n",
      "20    skin     each     beans      would     disease       NaN\n",
      "21    star    shade     child   shambles      trophy       NaN\n",
      "22   began     ribs     space  taillight     theater       NaN\n",
      "23    grew  forever  princess    quicken  OR theatre       NaN\n",
      "24    fine   freeze     piper   presence     athlete       NaN]\n"
     ]
    }
   ],
   "source": [
    "for pg in range(3,5):\n",
    "    print(pg)\n",
    "    df_new=tabula.read_pdf(\"Words_Bee.pdf\", pages=pg,area=(30,331,70,420))\n",
    "    x=str(df_new)\n",
    "    print(x)\n",
    "    def Lvl_chk(x):\n",
    "        num_lst =['ONE','TWO', 'THREE']\n",
    "        column_val=''\n",
    "    \n",
    "        for i in num_lst:\n",
    "            print('outside loop:',i)\n",
    "            if i in x:\n",
    "                print('xval',i)\n",
    "                column_val = i\n",
    "                return column_val\n",
    "        return None\n",
    "    \n",
    "    column_val =Lvl_chk(x)\n",
    "    if column_val:\n",
    "        print('Page read')\n",
    "        df_data=tabula.read_pdf(\"Words_Bee.pdf\",pages=pg)\n",
    "        print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Inp = {column_val : df_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'upset', 'motor', 'sprint', 'hatchling', 'swirled',\n",
       "       'sport', 'father', 'talking', 'awe', 'razz', 'amount', 'rich',\n",
       "       'jam', 'money', 'afar', 'followed', 'sighed', 'eel', 'mugs',\n",
       "       'couch', 'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble',\n",
       "       'sweat', 'entire', 'worse', 'dome', 'dinner', 'strands', 'cost',\n",
       "       'December', 'sandwich', 'tall', 'rats', 'chapter', 'sleek',\n",
       "       'sudden', 'duo', 'better', 'fed', 'chess', 'bottle', 'slither',\n",
       "       'gleaming', 'hit', 'sir', 'slimy', 'smart', 'combed', 'repress',\n",
       "       'peanut', 'boom', 'squeak', 'stared', 'patrol', 'clothes', 'cake',\n",
       "       'wave', 'friend', 'plopped', 'epic', 'either', 'bite', 'trunk',\n",
       "       'laptop', 'darted', 'vital', 'rely', 'noon', 'sleepy', 'movie',\n",
       "       'angry', 'window', 'chose', 'gummy', 'full', 'known', 'sidekick',\n",
       "       'pocket', 'belle', 'sting', 'huge', 'suffer', 'stuff', 'project',\n",
       "       'else', 'ray', 'born', 'double', 'least', 'goofy', 'picture',\n",
       "       'dusk', 'jumping', 'watch', 'little', 'remember', 'prepare',\n",
       "       'mops', 'damp', 'ahoy', 'felt', 'travel', 'percent', 'thanks',\n",
       "       'from', 'dream', 'summer', 'cranky', 'afraid', 'dash', 'hunch',\n",
       "       'whine', 'carefully', 'career', 'rescue', 'skin', 'each', 'beans',\n",
       "       'would', 'disease', nan, 'star', 'shade', 'child', 'shambles',\n",
       "       'trophy', nan, 'began', 'ribs', 'space', 'taillight', 'theater',\n",
       "       nan, 'grew', 'forever', 'princess', 'quicken', 'OR theatre', nan,\n",
       "       'fine', 'freeze', 'piper', 'presence', 'athlete', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample =np.array(df_data[0])\n",
    "\n",
    "\n",
    "new_list= np.concatenate( sample, axis=0 )\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.DataFrame(new_list,columns=[column_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hatchling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>freeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ONE\n",
       "0        train\n",
       "1        upset\n",
       "2        motor\n",
       "3       sprint\n",
       "4    hatchling\n",
       "..         ...\n",
       "145     freeze\n",
       "146      piper\n",
       "147   presence\n",
       "148    athlete\n",
       "149        NaN\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-16889f67b5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtabula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Words_Bee.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "df_data=tabula.read_pdf(\"Words_Bee.pdf\",pages=4)\n",
    "df_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gel</th>\n",
       "      <th>day</th>\n",
       "      <th>scorch</th>\n",
       "      <th>hear</th>\n",
       "      <th>sizzle</th>\n",
       "      <th>jotted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>upset</td>\n",
       "      <td>motor</td>\n",
       "      <td>sprint</td>\n",
       "      <td>hatchling</td>\n",
       "      <td>swirled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>father</td>\n",
       "      <td>talking</td>\n",
       "      <td>awe</td>\n",
       "      <td>razz</td>\n",
       "      <td>amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rich</td>\n",
       "      <td>jam</td>\n",
       "      <td>money</td>\n",
       "      <td>afar</td>\n",
       "      <td>followed</td>\n",
       "      <td>sighed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eel</td>\n",
       "      <td>mugs</td>\n",
       "      <td>couch</td>\n",
       "      <td>bowl</td>\n",
       "      <td>purple</td>\n",
       "      <td>sheen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fans</td>\n",
       "      <td>fair</td>\n",
       "      <td>nibble</td>\n",
       "      <td>sweat</td>\n",
       "      <td>entire</td>\n",
       "      <td>worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dome</td>\n",
       "      <td>dinner</td>\n",
       "      <td>strands</td>\n",
       "      <td>cost</td>\n",
       "      <td>December</td>\n",
       "      <td>sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tall</td>\n",
       "      <td>rats</td>\n",
       "      <td>chapter</td>\n",
       "      <td>sleek</td>\n",
       "      <td>sudden</td>\n",
       "      <td>duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>better</td>\n",
       "      <td>fed</td>\n",
       "      <td>chess</td>\n",
       "      <td>bottle</td>\n",
       "      <td>slither</td>\n",
       "      <td>gleaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit</td>\n",
       "      <td>sir</td>\n",
       "      <td>slimy</td>\n",
       "      <td>smart</td>\n",
       "      <td>combed</td>\n",
       "      <td>repress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peanut</td>\n",
       "      <td>boom</td>\n",
       "      <td>squeak</td>\n",
       "      <td>stared</td>\n",
       "      <td>patrol</td>\n",
       "      <td>clothes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cake</td>\n",
       "      <td>wave</td>\n",
       "      <td>friend</td>\n",
       "      <td>plopped</td>\n",
       "      <td>epic</td>\n",
       "      <td>either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bite</td>\n",
       "      <td>trunk</td>\n",
       "      <td>laptop</td>\n",
       "      <td>darted</td>\n",
       "      <td>vital</td>\n",
       "      <td>rely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>noon</td>\n",
       "      <td>sleepy</td>\n",
       "      <td>movie</td>\n",
       "      <td>angry</td>\n",
       "      <td>window</td>\n",
       "      <td>chose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gummy</td>\n",
       "      <td>full</td>\n",
       "      <td>known</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>pocket</td>\n",
       "      <td>belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sting</td>\n",
       "      <td>huge</td>\n",
       "      <td>suffer</td>\n",
       "      <td>stuff</td>\n",
       "      <td>project</td>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ray</td>\n",
       "      <td>born</td>\n",
       "      <td>double</td>\n",
       "      <td>least</td>\n",
       "      <td>goofy</td>\n",
       "      <td>picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dusk</td>\n",
       "      <td>jumping</td>\n",
       "      <td>watch</td>\n",
       "      <td>little</td>\n",
       "      <td>remember</td>\n",
       "      <td>prepare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mops</td>\n",
       "      <td>damp</td>\n",
       "      <td>ahoy</td>\n",
       "      <td>felt</td>\n",
       "      <td>travel</td>\n",
       "      <td>percent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thanks</td>\n",
       "      <td>from</td>\n",
       "      <td>dream</td>\n",
       "      <td>summer</td>\n",
       "      <td>cranky</td>\n",
       "      <td>afraid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dash</td>\n",
       "      <td>hunch</td>\n",
       "      <td>whine</td>\n",
       "      <td>carefully</td>\n",
       "      <td>career</td>\n",
       "      <td>rescue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>skin</td>\n",
       "      <td>each</td>\n",
       "      <td>beans</td>\n",
       "      <td>would</td>\n",
       "      <td>disease</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>star</td>\n",
       "      <td>shade</td>\n",
       "      <td>child</td>\n",
       "      <td>shambles</td>\n",
       "      <td>trophy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>began</td>\n",
       "      <td>ribs</td>\n",
       "      <td>space</td>\n",
       "      <td>taillight</td>\n",
       "      <td>theater</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>grew</td>\n",
       "      <td>forever</td>\n",
       "      <td>princess</td>\n",
       "      <td>quicken</td>\n",
       "      <td>OR theatre</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fine</td>\n",
       "      <td>freeze</td>\n",
       "      <td>piper</td>\n",
       "      <td>presence</td>\n",
       "      <td>athlete</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gel      day    scorch       hear      sizzle    jotted\n",
       "0    train    upset     motor     sprint   hatchling   swirled\n",
       "1    sport   father   talking        awe        razz    amount\n",
       "2     rich      jam     money       afar    followed    sighed\n",
       "3      eel     mugs     couch       bowl      purple     sheen\n",
       "4     fans     fair    nibble      sweat      entire     worse\n",
       "5     dome   dinner   strands       cost    December  sandwich\n",
       "6     tall     rats   chapter      sleek      sudden       duo\n",
       "7   better      fed     chess     bottle     slither  gleaming\n",
       "8      hit      sir     slimy      smart      combed   repress\n",
       "9   peanut     boom    squeak     stared      patrol   clothes\n",
       "10    cake     wave    friend    plopped        epic    either\n",
       "11    bite    trunk    laptop     darted       vital      rely\n",
       "12    noon   sleepy     movie      angry      window     chose\n",
       "13   gummy     full     known   sidekick      pocket     belle\n",
       "14   sting     huge    suffer      stuff     project      else\n",
       "15     ray     born    double      least       goofy   picture\n",
       "16    dusk  jumping     watch     little    remember   prepare\n",
       "17    mops     damp      ahoy       felt      travel   percent\n",
       "18  thanks     from     dream     summer      cranky    afraid\n",
       "19    dash    hunch     whine  carefully      career    rescue\n",
       "20    skin     each     beans      would     disease       NaN\n",
       "21    star    shade     child   shambles      trophy       NaN\n",
       "22   began     ribs     space  taillight     theater       NaN\n",
       "23    grew  forever  princess    quicken  OR theatre       NaN\n",
       "24    fine   freeze     piper   presence     athlete       NaN"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       gel      day    scorch       hear      sizzle    jotted\n",
       " 0    train    upset     motor     sprint   hatchling   swirled\n",
       " 1    sport   father   talking        awe        razz    amount\n",
       " 2     rich      jam     money       afar    followed    sighed\n",
       " 3      eel     mugs     couch       bowl      purple     sheen\n",
       " 4     fans     fair    nibble      sweat      entire     worse\n",
       " 5     dome   dinner   strands       cost    December  sandwich\n",
       " 6     tall     rats   chapter      sleek      sudden       duo\n",
       " 7   better      fed     chess     bottle     slither  gleaming\n",
       " 8      hit      sir     slimy      smart      combed   repress\n",
       " 9   peanut     boom    squeak     stared      patrol   clothes\n",
       " 10    cake     wave    friend    plopped        epic    either\n",
       " 11    bite    trunk    laptop     darted       vital      rely\n",
       " 12    noon   sleepy     movie      angry      window     chose\n",
       " 13   gummy     full     known   sidekick      pocket     belle\n",
       " 14   sting     huge    suffer      stuff     project      else\n",
       " 15     ray     born    double      least       goofy   picture\n",
       " 16    dusk  jumping     watch     little    remember   prepare\n",
       " 17    mops     damp      ahoy       felt      travel   percent\n",
       " 18  thanks     from     dream     summer      cranky    afraid\n",
       " 19    dash    hunch     whine  carefully      career    rescue\n",
       " 20    skin     each     beans      would     disease       NaN\n",
       " 21    star    shade     child   shambles      trophy       NaN\n",
       " 22   began     ribs     space  taillight     theater       NaN\n",
       " 23    grew  forever  princess    quicken  OR theatre       NaN\n",
       " 24    fine   freeze     piper   presence     athlete       NaN]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*df_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list=[]\n",
    "for item in df_data:\n",
    "    sample_list= ','.join(item)\n",
    "   \n",
    "\n",
    "hdr_lst=sample_list.split(',')\n",
    "hdr_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted', 'train',\n",
       "       'upset', 'motor', 'sprint', 'hatchling', 'swirled', 'sport',\n",
       "       'father', 'talking', 'awe', 'razz', 'amount', 'rich', 'jam',\n",
       "       'money', 'afar', 'followed', 'sighed', 'eel', 'mugs', 'couch',\n",
       "       'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble', 'sweat',\n",
       "       'entire', 'worse', 'dome', 'dinner', 'strands', 'cost', 'December',\n",
       "       'sandwich', 'tall', 'rats', 'chapter', 'sleek', 'sudden', 'duo',\n",
       "       'better', 'fed', 'chess', 'bottle', 'slither', 'gleaming', 'hit',\n",
       "       'sir', 'slimy', 'smart', 'combed', 'repress', 'peanut', 'boom',\n",
       "       'squeak', 'stared', 'patrol', 'clothes', 'cake', 'wave', 'friend',\n",
       "       'plopped', 'epic', 'either', 'bite', 'trunk', 'laptop', 'darted',\n",
       "       'vital', 'rely', 'noon', 'sleepy', 'movie', 'angry', 'window',\n",
       "       'chose', 'gummy', 'full', 'known', 'sidekick', 'pocket', 'belle',\n",
       "       'sting', 'huge', 'suffer', 'stuff', 'project', 'else', 'ray',\n",
       "       'born', 'double', 'least', 'goofy', 'picture', 'dusk', 'jumping',\n",
       "       'watch', 'little', 'remember', 'prepare', 'mops', 'damp', 'ahoy',\n",
       "       'felt', 'travel', 'percent', 'thanks', 'from', 'dream', 'summer',\n",
       "       'cranky', 'afraid', 'dash', 'hunch', 'whine', 'carefully',\n",
       "       'career', 'rescue', 'skin', 'each', 'beans', 'would', 'disease',\n",
       "       nan, 'star', 'shade', 'child', 'shambles', 'trophy', nan, 'began',\n",
       "       'ribs', 'space', 'taillight', 'theater', nan, 'grew', 'forever',\n",
       "       'princess', 'quicken', 'OR theatre', nan, 'fine', 'freeze',\n",
       "       'piper', 'presence', 'athlete', nan], dtype=object)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1=np.array(hdr_lst)\n",
    "sample =np.array(df_data[0])\n",
    "\n",
    "\n",
    "new_list= np.concatenate( sample, axis=0 )\n",
    "merged=np.append(arr1,sample)\n",
    "merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ONE': array(['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted', 'train',\n",
       "        'upset', 'motor', 'sprint', 'hatchling', 'swirled', 'sport',\n",
       "        'father', 'talking', 'awe', 'razz', 'amount', 'rich', 'jam',\n",
       "        'money', 'afar', 'followed', 'sighed', 'eel', 'mugs', 'couch',\n",
       "        'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble', 'sweat',\n",
       "        'entire', 'worse', 'dome', 'dinner', 'strands', 'cost', 'December',\n",
       "        'sandwich', 'tall', 'rats', 'chapter', 'sleek', 'sudden', 'duo',\n",
       "        'better', 'fed', 'chess', 'bottle', 'slither', 'gleaming', 'hit',\n",
       "        'sir', 'slimy', 'smart', 'combed', 'repress', 'peanut', 'boom',\n",
       "        'squeak', 'stared', 'patrol', 'clothes', 'cake', 'wave', 'friend',\n",
       "        'plopped', 'epic', 'either', 'bite', 'trunk', 'laptop', 'darted',\n",
       "        'vital', 'rely', 'noon', 'sleepy', 'movie', 'angry', 'window',\n",
       "        'chose', 'gummy', 'full', 'known', 'sidekick', 'pocket', 'belle',\n",
       "        'sting', 'huge', 'suffer', 'stuff', 'project', 'else', 'ray',\n",
       "        'born', 'double', 'least', 'goofy', 'picture', 'dusk', 'jumping',\n",
       "        'watch', 'little', 'remember', 'prepare', 'mops', 'damp', 'ahoy',\n",
       "        'felt', 'travel', 'percent', 'thanks', 'from', 'dream', 'summer',\n",
       "        'cranky', 'afraid', 'dash', 'hunch', 'whine', 'carefully',\n",
       "        'career', 'rescue', 'skin', 'each', 'beans', 'would', 'disease',\n",
       "        nan, 'star', 'shade', 'child', 'shambles', 'trophy', nan, 'began',\n",
       "        'ribs', 'space', 'taillight', 'theater', nan, 'grew', 'forever',\n",
       "        'princess', 'quicken', 'OR theatre', nan, 'fine', 'freeze',\n",
       "        'piper', 'presence', 'athlete', nan], dtype=object)}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1=np.array(hdr_lst)\n",
    "sample =np.array(df_data[0])\n",
    "\n",
    "\n",
    "\n",
    "merged=np.append(arr1,sample)\n",
    "dict_file={}\n",
    "one='ONE'\n",
    "dict_file[one]=merged\n",
    "dict_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted', 'train',\n",
       "       'upset', 'motor', 'sprint', 'hatchling', 'swirled', 'sport',\n",
       "       'father', 'talking', 'awe', 'razz', 'amount', 'rich', 'jam',\n",
       "       'money', 'afar', 'followed', 'sighed', 'eel', 'mugs', 'couch',\n",
       "       'bowl', 'purple', 'sheen', 'fans', 'fair', 'nibble', 'sweat',\n",
       "       'entire', 'worse', 'dome', 'dinner', 'strands', 'cost', 'December',\n",
       "       'sandwich', 'tall', 'rats', 'chapter', 'sleek', 'sudden', 'duo',\n",
       "       'better', 'fed', 'chess', 'bottle', 'slither', 'gleaming', 'hit',\n",
       "       'sir', 'slimy', 'smart', 'combed', 'repress', 'peanut', 'boom',\n",
       "       'squeak', 'stared', 'patrol', 'clothes', 'cake', 'wave', 'friend',\n",
       "       'plopped', 'epic', 'either', 'bite', 'trunk', 'laptop', 'darted',\n",
       "       'vital', 'rely', 'noon', 'sleepy', 'movie', 'angry', 'window',\n",
       "       'chose', 'gummy', 'full', 'known', 'sidekick', 'pocket', 'belle',\n",
       "       'sting', 'huge', 'suffer', 'stuff', 'project', 'else', 'ray',\n",
       "       'born', 'double', 'least', 'goofy', 'picture', 'dusk', 'jumping',\n",
       "       'watch', 'little', 'remember', 'prepare', 'mops', 'damp', 'ahoy',\n",
       "       'felt', 'travel', 'percent', 'thanks', 'from', 'dream', 'summer',\n",
       "       'cranky', 'afraid', 'dash', 'hunch', 'whine', 'carefully',\n",
       "       'career', 'rescue', 'skin', 'each', 'beans', 'would', 'disease',\n",
       "       nan, 'star', 'shade', 'child', 'shambles', 'trophy', nan, 'began',\n",
       "       'ribs', 'space', 'taillight', 'theater', nan, 'grew', 'forever',\n",
       "       'princess', 'quicken', 'OR theatre', nan, 'fine', 'freeze',\n",
       "       'piper', 'presence', 'athlete', nan], dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list=[]\n",
    "\n",
    "for item in df_data:\n",
    "    sample_list= ','.join(item)\n",
    "x=np.array(sample_list.split(','))\n",
    "y=np.array(df_data[0])\n",
    "x=np.append(x,y)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gel', 'day', 'scorch', 'hear', 'sizzle', 'jotted']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdr_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.item>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[]]*3\n",
    "a[0]=hdr_lst\n",
    "a[1] =x\n",
    "list(x)\n",
    "x.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['gel' 'day' 'scorch' 'hear' 'sizzle' 'jotted' 'train' 'upset' 'motor'\\n 'sprint' 'hatchling' 'swirled' 'sport' 'father' 'talking' 'awe' 'razz'\\n 'amount' 'rich' 'jam' 'money' 'afar' 'followed' 'sighed' 'eel' 'mugs'\\n 'couch' 'bowl' 'purple' 'sheen' 'fans' 'fair' 'nibble' 'sweat' 'entire'\\n 'worse' 'dome' 'dinner' 'strands' 'cost' 'December' 'sandwich' 'tall'\\n 'rats' 'chapter' 'sleek' 'sudden' 'duo' 'better' 'fed' 'chess' 'bottle'\\n 'slither' 'gleaming' 'hit' 'sir' 'slimy' 'smart' 'combed' 'repress'\\n 'peanut' 'boom' 'squeak' 'stared' 'patrol' 'clothes' 'cake' 'wave'\\n 'friend' 'plopped' 'epic' 'either' 'bite' 'trunk' 'laptop' 'darted'\\n 'vital' 'rely' 'noon' 'sleepy' 'movie' 'angry' 'window' 'chose' 'gummy'\\n 'full' 'known' 'sidekick' 'pocket' 'belle' 'sting' 'huge' 'suffer'\\n 'stuff' 'project' 'else' 'ray' 'born' 'double' 'least' 'goofy' 'picture'\\n 'dusk' 'jumping' 'watch' 'little' 'remember' 'prepare' 'mops' 'damp'\\n 'ahoy' 'felt' 'travel' 'percent' 'thanks' 'from' 'dream' 'summer'\\n 'cranky' 'afraid' 'dash' 'hunch' 'whine' 'carefully' 'career' 'rescue'\\n 'skin' 'each' 'beans' 'would' 'disease' nan 'star' 'shade' 'child'\\n 'shambles' 'trophy' nan 'began' 'ribs' 'space' 'taillight' 'theater' nan\\n 'grew' 'forever' 'princess' 'quicken' 'OR theatre' nan 'fine' 'freeze'\\n 'piper' 'presence' 'athlete' nan]\"]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=str(x).split('[]')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>scorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sizzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>freeze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>piper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1\n",
       "0   NaN       gel\n",
       "1   NaN       day\n",
       "2   NaN    scorch\n",
       "3   NaN      hear\n",
       "4   NaN    sizzle\n",
       "..   ..       ...\n",
       "151 NaN    freeze\n",
       "152 NaN     piper\n",
       "153 NaN  presence\n",
       "154 NaN   athlete\n",
       "155 NaN       NaN\n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "dataset = pd.DataFrame({'Index': []*10})\n",
    "\n",
    "prev='ONE'\n",
    "df2 = pd.DataFrame({prev:x})\n",
    "dataset =pd.concat([dataset,df2], ignore_index=True, axis=1)\n",
    "        \n",
    "\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
