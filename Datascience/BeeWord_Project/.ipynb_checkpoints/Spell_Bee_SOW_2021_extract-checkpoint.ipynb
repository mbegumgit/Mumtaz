{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#        # School of words 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Mar 21, 2021 5:24:42 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\r\n",
      "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\r\n",
      "Mar 21, 2021 5:24:43 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\r\n",
      "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page no: 1\n",
      "Page no: 2\n",
      "Page no: 3\n"
     ]
    }
   ],
   "source": [
    "file =input('Enter the file path /filename to extract:')\n",
    "page =int(input('Enter how many pages in PDF file:'))\n",
    "\n",
    "def Array_handling(df_data):\n",
    "    sample_list=''\n",
    "    for item in df_data:\n",
    "        sample_list= ','.join(item)\n",
    "        x=np.array(sample_list.split(','))\n",
    "        y=np.array(df_data[0])\n",
    "        return np.append(x,y)\n",
    "        \n",
    "def Read_Pdf(file,page) :      \n",
    "    words_array = []\n",
    "#file = 'Bee_Docs/Spelling Bee_School Of Word_2021_decrypt.pdf'\n",
    "    for pg in range(1,page+1):\n",
    "        data=tabula.read_pdf(file,pages=pg)\n",
    "        print('Reading Page no:',pg)\n",
    "        # Appending each page in an array\n",
    "        words_array=np.append(words_array,Array_handling(data))  \n",
    "    print('Writing into dataframe')\n",
    "    Output_df = pd.DataFrame({'Words':words_array})\n",
    "    Bee_Output_df = Output_df.copy()\n",
    "    Bee_Output_df.dropna(axis=0, inplace=True)\n",
    "    filt=Bee_Output_df.loc[Bee_Output_df['Words'].str.contains('Unnamed:')].index\n",
    "    Bee_Output_df.drop(filt,axis=0,inplace=True)\n",
    "    Bee_Output_df.reset_index(inplace=True)\n",
    "    Bee_Output_df.drop(['index'],axis=1,inplace=True)\n",
    "    return Bee_Output_df\n",
    "# Calling PDf read function     \n",
    "Bee_Output_df = Read_Pdf(file,page)\n",
    "Output_df = Bee_Output_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing OR  / ** suffixed/prefixxed  words from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#items = ['maharajah', 'Up OR', '*fff   OR','doctor','as-is-that', 'le cafe']\n",
    "def Orsplit(x):\n",
    "    match = re.findall('\\**([\\w+\\s*\\w*]*)\\s+OR|\\**(\\w+((\\s*|-)\\w+)*)',x)\n",
    "    for item in match[0]:\n",
    "        if item != '':\n",
    "            return item \n",
    "#for item in items:\n",
    " #   print(Orsplit(item))\n",
    "Bee_Output_df['Words'] = Bee_Output_df['Words'].apply(Orsplit)\n",
    "\n",
    "# Writing into CSV file\n",
    "Bee_Output_df.to_csv('Bee_Docs/2021_School of Words_Output.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
